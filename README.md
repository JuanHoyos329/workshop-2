# üéµ Workshop-2: Pipeline ETL de An√°lisis Musical Grammy & Spotify

## üìã Descripci√≥n del Proyecto

Este proyecto implementa un **pipeline ETL completo** que integra datos de los **Premios Grammy** y **Spotify** para realizar an√°lisis musical estrat√©gico. El sistema automatiza la extracci√≥n, transformaci√≥n y carga de datos utilizando **Apache Airflow**, Docker, y MySQL, culminando en un dashboard interactivo de Power BI.

### üéØ Objetivos

- Automatizar el proceso de integraci√≥n de datos Grammy y Spotify
- Realizar an√°lisis exploratorio de datos (EDA) sobre caracter√≠sticas musicales
- Identificar patrones de √©xito en la industria musical
- Proveer insights estrat√©gicos para decisiones de discogr√°ficas
- Crear un pipeline de datos escalable y reproducible

---

## üèóÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Data Sources  ‚îÇ
‚îÇ  Grammy + Spotify‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   EXTRACTION    ‚îÇ  ‚Üê extract.py (MySQL)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TRANSFORMATION  ‚îÇ  ‚Üê transformation.py
‚îÇ  - Normalizaci√≥n ‚îÇ
‚îÇ  - Merge Data   ‚îÇ
‚îÇ  - Feature Eng. ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      LOAD       ‚îÇ  ‚Üê load.py
‚îÇ  - MySQL DB     ‚îÇ
‚îÇ  - Google Drive ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ORQUESTACI√ìN   ‚îÇ  ‚Üê Apache Airflow
‚îÇ   (dag_etl.py)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  VISUALIZACI√ìN  ‚îÇ  ‚Üê Power BI Dashboard
‚îÇ   & AN√ÅLISIS    ‚îÇ     eda.ipynb
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÇ Estructura del Proyecto

```
workshop-2/
‚îÇ
‚îú‚îÄ‚îÄ dags/                           # Directorio de Airflow
‚îÇ   ‚îú‚îÄ‚îÄ dag_etl.py                 
‚îÇ   ‚îú‚îÄ‚îÄ extract.py                
‚îÇ   ‚îú‚îÄ‚îÄ transformation.py          
‚îÇ   ‚îú‚îÄ‚îÄ load.py                    
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  
‚îÇ   ‚îú‚îÄ‚îÄ authenticate_drive.py      
‚îÇ   ‚îú‚îÄ‚îÄ load_drive.py             
‚îÇ   ‚îú‚îÄ‚îÄ client_secret.json        
‚îÇ   ‚îú‚îÄ‚îÄ credentials.json           
‚îÇ   ‚îú‚îÄ‚îÄ spotify_dataset.csv       
‚îÇ   ‚îú‚îÄ‚îÄ the_grammy_awards.csv     
‚îÇ   ‚îî‚îÄ‚îÄ merged_grammy_spotify_clean.csv  
‚îÇ
‚îú‚îÄ‚îÄ data/                         
‚îú‚îÄ‚îÄ logs/                          
‚îú‚îÄ‚îÄ plugins/                      
‚îú‚îÄ‚îÄ dashboard/                     
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.pbix             
‚îÇ
‚îú‚îÄ‚îÄ eda.ipynb                      
‚îú‚îÄ‚îÄ docker-compose.yaml            
‚îú‚îÄ‚îÄ requirements.txt               
‚îú‚îÄ‚îÄ .env                           
‚îî‚îÄ‚îÄ README.md                      
```

---

## üîß Tecnolog√≠as Utilizadas

### Backend & Orquestaci√≥n
- **Apache Airflow 2.5.1** - Orquestaci√≥n del pipeline ETL
- **Python 3.x** - Lenguaje principal
- **Pandas** - Manipulaci√≥n y an√°lisis de datos
- **SQLAlchemy** - ORM para bases de datos

### Infraestructura
- **Docker & Docker Compose** - Containerizaci√≥n
- **PostgreSQL** - Metadata de Airflow
- **MySQL 8.0** - Base de datos principal
- **Redis** - Message broker para Celery

### Almacenamiento & APIs
- **Google Drive API** - Almacenamiento en la nube
- **PyDrive2** - Cliente Python para Google Drive

### An√°lisis & Visualizaci√≥n
- **Jupyter Notebook** - EDA interactivo
- **Matplotlib & Seaborn** - Visualizaciones
- **SciPy** - An√°lisis estad√≠stico
- **Power BI** - Dashboard empresarial

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

- Docker Desktop instalado
- Python 3.8+
- Cuenta de Google Cloud (para Google Drive API)
- 4GB RAM m√≠nimo
- 10GB espacio en disco

### 1. Clonar el Repositorio

```bash
git clone https://github.com/JuanHoyos329/workshop-2.git
cd workshop-2
```

### 2. Configurar Variables de Entorno

Crear archivo `.env` en la ra√≠z del proyecto:

```env
AIRFLOW_UID=50000
AIRFLOW_IMAGE_NAME=apache/airflow:2.5.1
```

### 3. Configurar Google Drive API

1. Ir a [Google Cloud Console](https://console.cloud.google.com/)
2. Crear un nuevo proyecto
3. Habilitar **Google Drive API**
4. Crear credenciales OAuth 2.0
5. Descargar `client_secret.json` y colocarlo en `dags/`
6. Ejecutar autenticaci√≥n:

```bash
python dags/authenticate_drive.py
```

### 4. Instalar Dependencias Python (Opcional - Local)

```bash
pip install -r requirements.txt
```

### 5. Iniciar Servicios con Docker

```bash
# Inicializar Airflow (primera vez)
docker-compose up airflow-init

# Levantar todos los servicios
docker-compose up -d

# Verificar estado de contenedores
docker-compose ps
```

### 6. Acceder a las Interfaces

- **Airflow UI**: http://localhost:8080
  - Usuario: `airflow`
  - Contrase√±a: `airflow`
  
- **Flower (Celery Monitor)**: http://localhost:5555

- **MySQL**: 
  - Host: `localhost`
  - Puerto: `3307`
  - Usuario: `airflow`
  - Contrase√±a: `airflow`
  - Base de datos: `grammy_db`

---

## üîÑ Pipeline ETL - Flujo de Trabajo

### DAG: `etl_workflow`

**Configuraci√≥n:**
- Inicio: 1 de agosto de 2025
- Frecuencia: Diaria (`@daily`)
- Catchup: Habilitado
- Max Active Runs: 1

### Tareas del Pipeline

#### 1Ô∏è‚É£ **Extracci√≥n** (`extract.py`)

**Funci√≥n:** Cargar datos Grammy a MySQL

- Lee `the_grammy_awards.csv`
- Detecta tipos de datos autom√°ticamente
- Crea tabla `grammy_awards` en MySQL
- Inserta registros con manejo de valores nulos
- **Resultado:** Tabla MySQL con datos Grammy

#### 2Ô∏è‚É£ **Transformaci√≥n** (`transformation.py`)

**Funci√≥n:** Merge inteligente y feature engineering

**Pasos:**
1. **Carga de datos:**
   - Spotify dataset desde CSV
   - Grammy dataset desde MySQL

2. **Limpieza:**
   - Eliminaci√≥n de duplicados
   - Normalizaci√≥n de texto (lowercase, espacios)
   - Manejo de colaboraciones (feat., &, and)

3. **Merge inteligente:**
   - Clasificaci√≥n de categor√≠as (canci√≥n vs √°lbum)
   - Coincidencia exacta y parcial
   - Mantener versi√≥n m√°s popular de cada track

4. **Feature Engineering:**
   - `explicit_label`: Explicit/Clean
   - `duration_minutes`: Duraci√≥n en minutos
   - `decade`: D√©cada de la canci√≥n
   - `popularity_range`: Categor√≠as de popularidad
   - `energy_level`: Nivel de energ√≠a
   - `dance_level`: Nivel de bailabilidad
   - `duration_category`: Categor√≠a por duraci√≥n
   - `mood`: Estado de √°nimo (Sad/Neutral/Happy)
   - `acousticness_level`: Electronic/Hybrid/Acoustic
   - `tempo_category`: Slow/Moderate/Fast/Very Fast

5. **Filtrado:**
   - Solo registros con datos completos (Grammy + Spotify)
   - Elimina registros sin informaci√≥n √∫til

**Resultado:** `merged_grammy_spotify_clean.csv` con datos listos para an√°lisis

#### 3Ô∏è‚É£ **Carga** (`load.py`)

**Funci√≥n:** Persistencia de datos procesados

**Operaciones:**
1. **Carga a MySQL:**
   - Tabla: `grammy_awards_cleaned`
   - M√©todo: SQLAlchemy `to_sql`
   - Estrategia: Replace (sobrescribe tabla)
   - Performance: ~500 registros por chunk

2. **Upload a Google Drive:**
   - Archivo: `merged_grammy_spotify_clean.csv`
   - Autenticaci√≥n: OAuth 2.0
   - Refresh autom√°tico de tokens
   - Folder ID configurable

**Resultado:** Datos disponibles en DB y Cloud

---

## üìä An√°lisis Exploratorio de Datos (EDA)

El notebook `eda.ipynb` contiene un an√°lisis completo en **ingl√©s** con las siguientes secciones:

### Estructura del EDA

1. **Data Loading**
   - Carga de datasets Spotify y Grammy
   - Validaci√≥n de estructura

2. **Spotify Dataset Analysis**
   - Overview de columnas y tipos
   - Calidad de datos (nulos, duplicados)
   - Estad√≠sticas descriptivas
   - Visualizaciones:
     - Top 10 artistas m√°s frecuentes
     - Distribuci√≥n de popularidad
     - Comparaci√≥n Explicit vs Non-Explicit
     - Distribuci√≥n de features de audio
     - Matriz de correlaci√≥n

3. **Grammy Dataset Analysis**
   - Estructura y tipos de datos
   - Categor√≠as m√°s frecuentes
   - Distribuci√≥n temporal de premios
   - Top 10 artistas con m√°s nominaciones
   - Distribuci√≥n Winner vs Nominee

4. **Outlier Detection**
   - Z-score analysis (|Z| > 3)
   - Boxplots para features num√©ricas
   - Identificaci√≥n de valores at√≠picos

5. **Key Findings Summary**
   - Resumen estad√≠stico completo
   - M√©tricas clave de ambos datasets

### Ejecutar el EDA

```bash
# Instalar dependencias
pip install jupyter pandas matplotlib seaborn scipy

# Iniciar Jupyter
jupyter notebook eda.ipynb
```

---

## üìà Dashboard Power BI

El archivo `dashboard/dashboard.pbix` contiene visualizaciones interactivas para an√°lisis estrat√©gico.

### Conexi√≥n a Datos

1. Abrir `dashboard.pbix` con Power BI Desktop
2. Configurar conexi√≥n MySQL:
   - Server: `localhost:3307`
   - Database: `grammy_db`
   - Table: `grammy_awards_cleaned`
3. Actualizar credenciales
4. Refresh datos

### Visualizaciones Sugeridas

- üìä KPIs: Total tracks, artistas, g√©neros
- üìâ Tendencias temporales de popularidad
- üé∏ Distribuci√≥n por g√©nero musical
- üèÜ An√°lisis de ganadores Grammy
- üéµ Caracter√≠sticas de audio por d√©cada
- üî• Top artistas y tracks

---

## üõ†Ô∏è Comandos √ötiles

### Docker

```bash
# Ver logs de Airflow
docker-compose logs airflow-scheduler -f

# Reiniciar servicios
docker-compose restart

# Detener todo
docker-compose down

# Eliminar vol√∫menes (CUIDADO: borra datos)
docker-compose down -v

# Reconstruir im√°genes
docker-compose build
```

### Airflow CLI

```bash
# Listar DAGs
docker-compose run airflow-worker airflow dags list

# Trigger manual del DAG
docker-compose run airflow-worker airflow dags trigger etl_workflow

# Ver estado de tareas
docker-compose run airflow-worker airflow tasks list etl_workflow
```

### MySQL

```bash
# Conectar a MySQL desde terminal
docker exec -it workshop-2-mysql-1 mysql -u airflow -pairflow grammy_db

# Consultas √∫tiles
SHOW TABLES;
SELECT COUNT(*) FROM grammy_awards_cleaned;
DESCRIBE grammy_awards_cleaned;
```

---

## üìù Configuraci√≥n de Base de Datos

### Conexi√≥n MySQL en `config.py`

```python
import mysql.connector

def get_db():
    return mysql.connector.connect(
        host="mysql",  # Nombre del servicio en docker-compose
        port=3306,
        user="airflow",
        password="airflow",
        database="grammy_db"
    )

def get_db_connection():
    return mysql.connector.connect(
        host="mysql",
        port=3306,
        user="airflow",
        password="airflow",
        database="grammy_db"
    )
```

---

## üîç Casos de Uso

### 1. An√°lisis de Tendencias Musicales
- Identificar caracter√≠sticas de √©xito
- Evoluci√≥n de g√©neros por d√©cada
- Predicci√≥n de popularidad

### 2. Estrategia de Discogr√°fica
- Perfiles de artistas exitosos
- Caracter√≠sticas √≥ptimas por g√©nero
- Timing de lanzamientos

### 3. An√°lisis de Premios
- Correlaci√≥n Grammy - Popularidad Spotify
- Categor√≠as m√°s competitivas
- Patrones de nominaciones

### 4. Feature Engineering
- Variables derivadas para ML
- Segmentaci√≥n de audiencias
- Clustering de canciones similares

---

## üêõ Troubleshooting

### Error: "No module named 'pandas'"
```bash
# Verificar que requirements.txt est√© en la imagen
docker-compose build --no-cache
docker-compose up -d
```

### Error de conexi√≥n MySQL
```bash
# Verificar que MySQL est√© healthy
docker-compose ps

# Revisar logs de MySQL
docker-compose logs mysql
```

### Error de autenticaci√≥n Google Drive
```bash
# Re-autenticar
python dags/authenticate_drive.py

# Verificar que credentials.json existe
ls -la dags/credentials.json
```

### Airflow no aparece en http://localhost:8080
```bash
# Verificar puerto disponible
netstat -an | findstr 8080  # Windows

# Verificar logs
docker-compose logs airflow-webserver
```

## üë• Autor

- **Juan Hoyos** - [@JuanHoyos329](https://github.com/JuanHoyos329)

**‚≠ê Si este proyecto te fue √∫til, considera darle una estrella en GitHub!**